{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "F9wbpzgQR9S6",
    "outputId": "c2ac8bc4-4571-4074-8229-75400192ef74"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import h5py\n",
    "\n",
    "import librosa\n",
    "from librosa.core import audio\n",
    "\n",
    "import numpy as np\n",
    "from numpy.core.fromnumeric import shape\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "\n",
    "from torch import FloatTensor, unsqueeze\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.nn.modules.activation import ReLU, Softplus\n",
    "\n",
    "from torch.nn.modules import activation, padding\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.nn.modules import loss\n",
    "\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-V-dh8UkGH-",
    "outputId": "69e91223-6966-44ac-ac47-4984848cd30a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QRkjTFRmY46"
   },
   "outputs": [],
   "source": [
    "# datafetcher.py\n",
    "\n",
    "def tensor_size(x):\n",
    "    return list(x.size())\n",
    "\n",
    "class DataFetcher:\n",
    "    def __init__(self):\n",
    "        self.wavelist_dict = {}\n",
    "        self.train_dict = {}\n",
    "        self.test_dict = {}\n",
    "        self.num_samples = 0\n",
    "\n",
    "        self.train_tensor_list = []\n",
    "        self.test_tensor_list = []\n",
    "\n",
    "        # Replace with path to your train/test data\n",
    "        self.tensor_train_path = '/content/drive/My Drive/data/processed_train.hdf5'\n",
    "        self.tensor_test_path = '/content/drive/My Drive/data/processed_test.hdf5'\n",
    "\n",
    "        self.device = 'gpu'\n",
    "\n",
    "    def get_train_data(self):\n",
    "        hf = h5py.File(self.tensor_train_path, 'r')\n",
    "        return hf['train']\n",
    "\n",
    "    def get_test_data(self):\n",
    "        hf = h5py.File(self.tensor_test_path, 'r')\n",
    "        return hf['test']\n",
    "\n",
    "    def get_train_test_data(self):\n",
    "        train_data = self.get_train_data()\n",
    "        test_data = self.get_test_data()\n",
    "\n",
    "        X_train = FloatTensor([train_data[i] for i in range(0, len(train_data), 2)])\n",
    "        y_train = FloatTensor([train_data[i] for i in range(1, len(train_data), 2)])\n",
    "\n",
    "        X_test = FloatTensor([test_data[i] for i in range(0, len(test_data), 2)])\n",
    "        y_test = FloatTensor([test_data[i] for i in range(1, len(test_data), 2)])\n",
    "        return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4gZjxSAJL6n"
   },
   "outputs": [],
   "source": [
    "# utils.py\n",
    "\n",
    "def tensor_size(x):\n",
    "    return list(x.size())\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, x, y, batch_size=16, window_length=4096):\n",
    "        self.x, self.y = x, y\n",
    "        self.window_length = window_length # 4096\n",
    "        self.hop_length = window_length//2 # 2048\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "            \n",
    "    def window_time_series(self, x, frame_length, hop_length):\n",
    "        '''Window time series, overlapping'''\n",
    "        blocks = []\n",
    "        n = list(x.size())[0]\n",
    "        ilo = range(0, n, hop_length)\n",
    "        ihi = range(frame_length, n+1, hop_length)\n",
    "        ilohi = zip(ilo, ihi)\n",
    "        blocks = [x[ilo:ihi] for ilo, ihi in ilohi]\n",
    "        return torch.stack(blocks, 0)\n",
    "\n",
    "    def slicing(self, x):\n",
    "        x = functional.pad(x, (self.window_length//2, self.window_length//2), mode='constant')\n",
    "\n",
    "        # Window the time series\n",
    "        return self.window_time_series(x, self.window_length, self.hop_length)\n",
    "\n",
    "    def ts(self, x):\n",
    "        return list(x.size())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = torch.zeros((self.batch_size, self.window_length, 1))\n",
    "        batch_y = torch.zeros((self.batch_size, self.window_length, 1))\n",
    "\n",
    "        x_w = self.x[idx].reshape(len(self.x[idx]))\n",
    "        y_w = self.y[idx].reshape(len(self.y[idx]))\n",
    "\n",
    "        x_w = self.slicing(x_w)\n",
    "        y_w = self.slicing(y_w)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            batch_x[i] = x_w[i].reshape(self.window_length,1)\n",
    "            batch_y[i] = y_w[i].reshape(self.window_length,1)\n",
    "\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUXkiPvXmtBc"
   },
   "outputs": [],
   "source": [
    "# layers.py\n",
    "\n",
    "class SAAF(nn.Module):\n",
    "    def __init__(self, break_points, break_range, magnitude):\n",
    "        super(SAAF, self).__init__()\n",
    "        self.break_range = break_range\n",
    "        self.magnitude = magnitude\n",
    "        self.break_points = list(torch.linspace(-self.break_range, self.break_range, break_points, dtype=torch.float32, device=torch.device(\"cuda:0\")))\n",
    "        self.num_segs = int(len(self.break_points) / 2)\n",
    "    \n",
    "    def basisf(self, x, s, e):\n",
    "        cp_start = torch.less_equal(s, x).float()\n",
    "        cp_end = torch.greater(e, x).float()\n",
    "\n",
    "        output = self.magnitude * (0.5 * (x - s)**2 * cp_start\n",
    "                                     * cp_end + ((e - s) * (x - e) + 0.5 * (e - s)**2) * (1 - cp_end))\n",
    "\n",
    "        return output.type(torch.cuda.FloatTensor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_shape = list(x.size())\n",
    "        self.kernel_dim = (self.num_segs + 1, input_shape[2])\n",
    "\n",
    "        self.kernel = nn.Parameter(data=torch.zeros(self.kernel_dim, device=torch.device(\"cuda:0\")), requires_grad=True)\n",
    "\n",
    "        output = torch.multiply(x, self.kernel[-1])\n",
    "\n",
    "        for segment in range(0, self.num_segs):\n",
    "            output += torch.multiply(self.basisf(x, self.break_points[segment * 2], self.break_points[segment * 2 + 1]), self.kernel[segment])\n",
    "\n",
    "        return output\n",
    "\n",
    "class Deconvolution(nn.Module):\n",
    "    def __init__(self, filters, kernel_size, conv_layer,\n",
    "                    strides=1,\n",
    "                    padding='valid'):\n",
    "        super(Deconvolution, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "\n",
    "        self.filters = filters\n",
    "        self.strides = (strides,)\n",
    "        self.padding = padding\n",
    "        self.input_dim = None\n",
    "        self.input_length = None\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv_layer = conv_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        gc.collect()\n",
    "        input_dim = x.shape[-1]\n",
    "        self.kernel_shape = (self.kernel_size, input_dim, self.filters)\n",
    "\n",
    "        x = torch.unsqueeze(x, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "\n",
    "        W = torch.unsqueeze(self.conv_layer.weight, -1)\n",
    "\n",
    "        W = W.permute(1, 0, 2, 3)\n",
    "\n",
    "        bias_data = torch.zeros(self.filters, device=torch.device(\"cuda:0\"))\n",
    "\n",
    "        conv2 = nn.Conv2d(self.filters, 1, self.kernel_size, padding=self.padding, bias=True, padding_mode='zeros', dtype=None, device=torch.device(\"cuda:0\"))\n",
    "        conv2.weight =  nn.Parameter(data=W, requires_grad=True)\n",
    "\n",
    "        output = conv2(x)\n",
    "        output = torch.squeeze(output, 3)\n",
    "\n",
    "        return output.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "class Convolution1D_Locally_Connected(nn.Module):\n",
    "    def __init__(self, filters, kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='valid',\n",
    "                    dilation_rate=1):\n",
    "        super(Convolution1D_Locally_Connected, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        self.filters = filters\n",
    "        self.strides = (strides,)\n",
    "        self.padding = padding\n",
    "        self.data_format = 'channels_last'\n",
    "        self.dilation_rate = (dilation_rate,)\n",
    "        self.activation = 'linear'\n",
    "        self.input_dim = None\n",
    "        self.input_length = None\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernel_shape = (filters, 1, kernel_size)\n",
    "\n",
    "        self.kernel = nn.Parameter(data=torch.zeros(self.kernel_shape, device=torch.device(\"cuda:0\")), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.kernel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.split(x, 1, dim=1)\n",
    "        W = torch.split(self.kernel, 1, dim=0)\n",
    "\n",
    "        out_shape = [self.filters]\n",
    "        out_shape.extend(list(x[0].shape))\n",
    "        outputs = torch.zeros(out_shape)\n",
    "\n",
    "        for i in range(self.filters):\n",
    "            x_conv1 = nn.Conv1d(1, 1, self.kernel_size, stride=1, padding='same', dilation=1, groups=1, bias=True, padding_mode='zeros', dtype=None, device=torch.device(\"cuda:0\"))\n",
    "            x_conv1.weight = nn.Parameter(data=W[i], requires_grad=True)\n",
    "            x_conv1.bias = nn.Parameter(data=torch.zeros(1, device=torch.device(\"cuda:0\")), requires_grad=True)\n",
    "            outputs[i] = x_conv1(x[i])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class BatchMaxPooling1d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(BatchMaxPooling1d, self).__init__()\n",
    "\n",
    "        self.device =torch.device(\"cuda:0\")\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_shape = list(x.shape)\n",
    "        out_shape = in_shape[:-1]\n",
    "        out_shape.extend([in_shape[-1]//self.kernel_size])\n",
    "\n",
    "        output = torch.zeros(out_shape, device=torch.device(\"cuda:0\"))\n",
    "        for i in range(in_shape[0]):\n",
    "            output[i] = nn.MaxPool1d(self.kernel_size)(torch.squeeze(x[i], 0))\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class LatentSpace_DNN_LocallyConnected_Dense(nn.Module):\n",
    "    def __init__(self, units,\n",
    "                    activation=None,\n",
    "                    use_bias=True):\n",
    "        super(LatentSpace_DNN_LocallyConnected_Dense, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.use_bias = use_bias\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_shape = list(x.size())\n",
    "        input_dim = input_shape[-1]\n",
    "        self.split = input_shape[1]\n",
    "\n",
    "        kernels = [nn.Parameter(data=torch.zeros(input_dim, self.units, device=torch.device(\"cuda:0\")), requires_grad=True) for i in range(self.split)]\n",
    "        self.kernel = torch.cat(kernels, -1)\n",
    "\n",
    "        biases = [nn.Parameter(data=torch.zeros(self.units, device=torch.device(\"cuda:0\")), requires_grad=True) for i in range(self.split)]\n",
    "        self.bias = torch.cat(biases, -1)\n",
    "\n",
    "        split_input = torch.split(x, 1, dim=1)\n",
    "        W = torch.split(self.kernel, self.units, dim=1)\n",
    "        b = torch.split(self.bias, self.units, dim=0)\n",
    "\n",
    "        outputs = []\n",
    "        for i,j in enumerate(split_input):\n",
    "            output = torch.matmul(torch.squeeze(j), W[i]) + b[i]\n",
    "            if self.activation is not None:\n",
    "                output = self.activation(output)\n",
    "            outputs.append(output)\n",
    "\n",
    "        return_val = torch.cat(outputs, 1)\n",
    "\n",
    "        return return_val.view(input_shape[0], self.split, input_dim)\n",
    "\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, layer, batch_first=False, **kwargs):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.layer = layer\n",
    "        self.batch_first = batch_first\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' x size: (batch_size, channels, 1)\n",
    "            Dense:  < x, in_features, out_features, activation >'''\n",
    "        if self.kwargs['layer_name'] == 'Dense':\n",
    "            in_features = self.kwargs['in_features']\n",
    "            out_features = self.kwargs['out_features']\n",
    "            activation = self.kwargs['activation']\n",
    "            c_out = self.layer(x, in_features, out_features, activation)\n",
    "            return c_out\n",
    "        return None\n",
    "\n",
    "class UpSampling1D(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(UpSampling1D, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.Upsample(size=self.size, mode='linear')(x)\n",
    "\n",
    "class Multiply(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Multiply, self).__init__()\n",
    "\n",
    "    def forward(self, tensors):\n",
    "        result = torch.ones(tensors[0].size(), device=torch.device(\"cuda:0\"))\n",
    "        for t in tensors:\n",
    "            result *= t\n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rz8DoOVJLdQ-"
   },
   "outputs": [],
   "source": [
    "# network.py\n",
    "\n",
    "class DistortionNetwork(nn.Module):\n",
    "    def __init__(self, window_length, filters, kernel_size, learning_rate):\n",
    "        super(DistortionNetwork, self).__init__()\n",
    "        self.window_length = window_length\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.conv = nn.Conv1d(1, self.filters, self.kernel_size, stride=1, padding='same', padding_mode='zeros')\n",
    "        self.convolution1d_locally_connected = Convolution1D_Locally_Connected(self.filters, 2 * self.kernel_size)\n",
    "        self.dense_layer = LatentSpace_DNN_LocallyConnected_Dense(self.window_length//64, activation=nn.ReLU)\n",
    "        self.deconvolution = Deconvolution(1, self.kernel_size, self.conv, padding='same')\n",
    "\n",
    "        self.conv.to(torch.device(\"cuda:0\"))\n",
    "        self.convolution1d_locally_connected.to(torch.device(\"cuda:0\"))\n",
    "        self.dense_layer.to(torch.device(\"cuda:0\"))\n",
    "        self.deconvolution.to(torch.device(\"cuda:0\"))\n",
    "\n",
    "    def permute_dims(self, x):\n",
    "        # pytorch initializes layer tensors in column major format.\n",
    "        return x.permute(0, 2, 1)\n",
    "\n",
    "    def Dense(self, x, in_features, out_features, activation=None):\n",
    "        if activation is not None:\n",
    "            return activation()(nn.Linear(in_features, out_features, device=torch.device(\"cuda:0\"))(x))\n",
    "        return nn.Linear(in_features, out_features, device=torch.device(\"cuda:0\"))(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.permute_dims(x)\n",
    "        x_conv = self.conv(x)\n",
    "        x_abs = torch.abs(x_conv)\n",
    "\n",
    "        M = self.convolution1d_locally_connected(x_abs)\n",
    "        M = nn.Softplus()(M)\n",
    "        M = M.permute(1, 0, 2, 3)\n",
    "\n",
    "        P = x_conv\n",
    "\n",
    "        Z = BatchMaxPooling1d(self.window_length//64)(M)\n",
    "\n",
    "        Z = LatentSpace_DNN_LocallyConnected_Dense(self.window_length//64)(Z)\n",
    "\n",
    "        Z = TimeDistributed(layer=self.Dense, batch_first=True,\n",
    "                            in_features=tensor_size(Z)[-1],\n",
    "                            out_features=self.window_length//64,\n",
    "                            activation=nn.Softplus, layer_name='Dense')(Z)\n",
    "\n",
    "        M_ = UpSampling1D(self.window_length)(Z)\n",
    "        \n",
    "        Y_ = Multiply()([P, M_])\n",
    "\n",
    "        Y_ = self.permute_dims(Y_)\n",
    "        Y_ = self.Dense(Y_, tensor_size(Y_)[-1], self.filters, nn.ReLU)\n",
    "        Y_ = self.Dense(Y_, tensor_size(Y_)[-1], self.filters//2, nn.ReLU)\n",
    "        Y_ = self.Dense(Y_, tensor_size(Y_)[-1], self.filters//2, nn.ReLU)\n",
    "        Y_ = self.Dense(Y_, tensor_size(Y_)[-1], self.filters//2, nn.ReLU)\n",
    "        Y_ = self.Dense(Y_, tensor_size(Y_)[-1], self.filters)\n",
    "\n",
    "\n",
    "        Y_ = SAAF(break_points=25, break_range=0.2, magnitude=100)(Y_)\n",
    "\n",
    "        output = Deconvolution(self.filters, self.kernel_size, self.conv, padding='same')(Y_)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O70AQ-b7LsRV"
   },
   "outputs": [],
   "source": [
    "# main.py\n",
    "def save_model_checkpoint(path, epoch, model_state_dict, optimizer_state_dict):\n",
    "    torch.save({\n",
    "          'epoch': epoch,\n",
    "          'model_state_dict': model_state_dict,\n",
    "          'optimizer_state_dict': optimizer_state_dict,\n",
    "    }, path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Model Checkpoint Path\n",
    "    CHK_PATH = '/content/drive/My Drive/checkpoints/distortion_dnn_model.pt'\n",
    "    BACKUP_CHK_PATH = '/content/drive/My Drive/checkpoints/distortion_dnn_model_backup.pt'\n",
    "\n",
    "    checkpoint = None\n",
    "    try:\n",
    "        checkpoint = torch.load(CHK_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No model checkpoint found. Starting afresh....\")\n",
    "\n",
    "    # Parameters\n",
    "    epochs = 2000\n",
    "    div = 1\n",
    "    window_length = 4096\n",
    "    filters = 128\n",
    "    kernel_size = 64\n",
    "    learning_rate = 0.0001\n",
    "    batch_size = 16\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Get train, test data\n",
    "    df = DataFetcher()\n",
    "    X_train, X_test, y_train, y_test = df.get_train_test_data()\n",
    "\n",
    "    # Load into neural network\n",
    "    distortion_network = DistortionNetwork(window_length, filters, kernel_size, learning_rate)\n",
    "    distortion_network.to(torch.device(\"cuda:0\"))\n",
    "\n",
    "    # Loss function and Optimizer\n",
    "    loss_function = nn.L1Loss() # Mean Absolute Error\n",
    "    optimizer = torch.optim.SGD(distortion_network.parameters(), lr=learning_rate)\n",
    "\n",
    "    # If checkpoint exists load from that.\n",
    "\n",
    "    train_generator = DataGenerator(X_train, y_train, batch_size=batch_size, window_length=window_length)\n",
    "    test_generator = DataGenerator(X_test, y_test, batch_size=batch_size, window_length=window_length)\n",
    "\n",
    "    epoch = 0\n",
    "    if checkpoint is not None:\n",
    "        epoch = checkpoint['epoch']\n",
    "        distortion_network.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    while epoch < epochs:\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_generator):\n",
    "            input_audio, output_audio = data\n",
    "            input_audio, output_audio = input_audio.to(device), output_audio.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #print(\"Begin forward pass....\")\n",
    "            network_output_audio = distortion_network(input_audio)\n",
    "            #print(\"End forward pass....\")\n",
    "            mae_loss = loss_function(network_output_audio, output_audio)\n",
    "            mae_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            div = 10\n",
    "            running_loss += 20 * mae_loss.item()\n",
    "            if i != 0 and i % div == 0:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss))\n",
    "                running_loss = 0.0\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Saved backup checkpoint with epochs \", (epoch + 1), \" completed.\")\n",
    "            save_model_checkpoint(BACKUP_CHK_PATH, epoch, distortion_network.state_dict(), optimizer.state_dict())\n",
    "        print(\"Saved checkpoint with epochs \", (epoch + 1), \" completed.\")\n",
    "        save_model_checkpoint(CHK_PATH, epoch, distortion_network.state_dict(), optimizer.state_dict())\n",
    "        epoch += 1\n",
    "\n",
    "    print(\"Finished training....\")\n",
    "\n",
    "    '''If network trains through all epochs the running loss should\n",
    "    be negligible for every batch\n",
    "    '''\n",
    "    for i, data in enumerate(test_generator):\n",
    "        input_audio, output_audio = data\n",
    "        input_audio, output_audio = input_audio.to(device), output_audio.to(device)\n",
    "        network_output_audio = distortion_network(input_audio)\n",
    "\n",
    "        mae_loss = loss_function(network_output_audio, output_audio)\n",
    "\n",
    "        running_loss += 1000 * mae_loss.item()\n",
    "\n",
    "        if i != 0 and i % div == 0:\n",
    "            print('[%d, %5d] loss on test data: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8quMF02MIzy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DistortionDNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
